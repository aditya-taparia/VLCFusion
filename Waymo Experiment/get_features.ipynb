{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import json\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mmengine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=\"YOUR_API_KEY\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_file = 'YOUR_PATH/refined_conditions.json'\n",
    "\n",
    "with open(questions_file, 'r') as f:\n",
    "    questions_list = json.load(f)\n",
    "    \n",
    "# formatted_questions = \"\\n\".join([\"- \" + question for question in questions_list])\n",
    "formatted_questions = \"\\n\".join([f\"{i+1}. {question}\" for i, question in enumerate(questions_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'YOUR_PATH/LidarTraining/night-day-frames/training/image_0/'\n",
    "anno_est = 'YOUR_PATH/LidarTraining/night-day-frames/waymo_infos_train.pkl'\n",
    "data_list = mmengine.load(anno_est)['data_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conditions(image, retry_count=0, max_retries=3):\n",
    "    \"\"\" \n",
    "    Get the vlm conditions from the image\n",
    "    \"\"\"\n",
    "    \n",
    "    if hasattr(image, \"detach\"):\n",
    "        image = image.detach().cpu().numpy()\n",
    "        if image.ndim == 3 and image.shape[0] in [1, 3]:\n",
    "            image = np.transpose(image, (1, 2, 0))\n",
    "        if image.dtype in [np.float32, np.float64]:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "\n",
    "    if isinstance(image, np.ndarray):\n",
    "        if image.ndim == 3 and image.shape[0] in [1, 3]:\n",
    "            image = np.transpose(image, (1, 2, 0))\n",
    "        try:\n",
    "            image = Image.fromarray(image)\n",
    "        except Exception as e:\n",
    "            raise ValueError(\n",
    "                \"Failed to convert numpy array to PIL image. Ensure the array has the correct shape and dtype.\"\n",
    "            ) from e\n",
    "    \n",
    "    def encode_image(image):\n",
    "        buffer = BytesIO()\n",
    "        image.save(buffer, format=\"JPEG\")\n",
    "        buffer.seek(0) \n",
    "        return base64.b64encode(buffer.read()).decode(\"utf-8\")\n",
    "\n",
    "    image_encoded = encode_image(image)\n",
    "    conditions = []\n",
    "    \n",
    "    message_text = (\n",
    "        \"Answer the following questions based on the given image:\\n\"\n",
    "        \"## Questions:\\n\"\n",
    "        f\"{formatted_questions}\\n\\n\"\n",
    "        f\"IMPORTANT: Your answer must be a JSON object with exactly {len(questions_list)} keys. \"\n",
    "        f\"The keys should be the numbers from 1 to {len(questions_list)} (as strings) and each value must be a boolean (True or False), one for each question, and nothing else. \"\n",
    "        \"The image is provided after these questions.\"\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        # model=\"gpt-4o\",\n",
    "        model=\"gpt-4o-2024-11-20\",\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"system\",\n",
    "            # \"content\": \"You are a highly specialized assistant that provides concise answers to specific questions about images. For each question, respond with either True or False only. Provide your answer as a JSON list of booleans. Do not provide additional context or descriptions.\"\n",
    "            \"content\": (\n",
    "                    \"You are a highly specialized assistant that provides concise answers to specific questions about images. \"\n",
    "                    \"For each question, respond with either True or False only. \"\n",
    "                    \"Provide your answer as a JSON object with keys corresponding to the question numbers (from 1 to \"\n",
    "                    f\"{len(questions_list)}). Do not provide additional context or descriptions.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": message_text,\n",
    "                # \"Answer the following questions based on the given image:\\n## Questions:\\n\"\n",
    "                #         \"- Do the input image depicts daytime based on the lighting conditions?\\n\"\n",
    "                #         \"- Is the weather clear in the input (not raining)?\\n\"\n",
    "                #         \"- Is the input image taken in a urban area?\\n\"\n",
    "                #         \"- Image:\\n\"\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{image_encoded}\",\n",
    "                },\n",
    "                },\n",
    "            ],\n",
    "            }\n",
    "        ],\n",
    "        )\n",
    "    \n",
    "    if response.choices[0].message.content is None:\n",
    "        return get_conditions(image, retry_count=retry_count, max_retries=max_retries)\n",
    "    \n",
    "    response_text = response.choices[0].message.content.strip()\n",
    "    \n",
    "    response_text = re.sub(r\"```(json)?\", \"\", response_text).strip()\n",
    "    response_text = re.sub(r\"```\", \"\", response_text).strip()\n",
    "    try:\n",
    "        conditions = json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        # conditions = [item.strip() for item in response_text.strip(\"[]\").split(\",\")]\n",
    "        conditions_list = [item.strip() for item in response_text.strip(\"[]\").split(\",\")]\n",
    "        conditions = {str(i+1): (True if str(item).strip().lower() == \"true\" else False)\n",
    "                      for i, item in enumerate(conditions_list)}\n",
    "    \n",
    "    # conditions = [True if str(item).strip().lower() == \"true\" else False for item in conditions]\n",
    "    \n",
    "    # # Check if the response length matches the number of questions\n",
    "    # if len(conditions) != len(questions_list):\n",
    "    #     if retry_count < max_retries:\n",
    "    #         print(f\"Mismatch in response length (got {len(conditions)} vs expected {len(questions_list)}). Retrying {retry_count+1}/{max_retries}...\")\n",
    "    #         time.sleep(0.5)\n",
    "    #         return get_conditions(image, retry_count=retry_count+1, max_retries=max_retries)\n",
    "    #     else:\n",
    "    #         raise ValueError(\"Response length does not match the number of questions even after retries.\")\n",
    "    #         # return conditions\n",
    "\n",
    "    # return conditions\n",
    "    \n",
    "    if not isinstance(conditions, dict) or len(conditions.keys()) != len(questions_list):\n",
    "        if retry_count < max_retries:\n",
    "            print(f\"Mismatch in response structure (got {len(conditions) if isinstance(conditions, dict) else 'non-dict'} vs expected {len(questions_list)}). Retrying {retry_count+1}/{max_retries}...\")\n",
    "            time.sleep(0.5)\n",
    "            return get_conditions(image, retry_count=retry_count+1, max_retries=max_retries)\n",
    "        else:\n",
    "            # raise ValueError(\"Response structure does not match the number of questions even after retries.\")\n",
    "            print(\"Response structure does not match the number of questions even after retries.\")\n",
    "            return []\n",
    "    \n",
    "    sorted_conditions = [conditions[str(i+1)] for i in range(len(questions_list))]\n",
    "    return sorted_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def process_img_info(data):\n",
    "    img_idx = data['sample_idx']\n",
    "    \n",
    "    img_path = data['images']['CAM_FRONT']['img_path']\n",
    "    img_path = root_path + img_path\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    conditions = get_conditions(img)\n",
    "    \n",
    "    # Sleep to avoid rate limit\n",
    "    time.sleep(0.75)\n",
    "\n",
    "    return {\n",
    "        'image_idx': img_idx,\n",
    "        'image_path': img_path,\n",
    "        'conditions': conditions,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_data = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "    results = list(tqdm(executor.map(process_img_info, data_list), total=len(data_list)))\n",
    "\n",
    "jsonl_data.extend(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of conditions for each data point\n",
    "for data in jsonl_data:\n",
    "    if len(data['conditions']) != len(questions_list):\n",
    "        print(f\"Image {data['image_idx']} has {len(data['conditions'])} conditions instead of {len(questions_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to a jsonl file\n",
    "with open('YOUR_PATH/night-day_training.jsonl', 'w') as f:\n",
    "    for item in jsonl_data:\n",
    "        f.write(json.dumps(item) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
