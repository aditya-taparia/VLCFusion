{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppresses INFO, WARNING, and ERROR messages -> Supress tensorflow warnings\n",
    "from os import path as osp\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "if not tf.executing_eagerly():\n",
    "  tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "from waymo_open_dataset.utils import range_image_utils, transform_utils\n",
    "from waymo_open_dataset.utils.frame_utils import parse_range_image_and_camera_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed=0, deterministic = True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation1 = 'night'\n",
    "# variation2 = 'day'\n",
    "# type_ = 'validation'\n",
    "\n",
    "data_path = '/mnt/data/ataparia/waymo_perception_dataset_v1_4_3'\n",
    "save_path = f'/mnt/data/ataparia/LidarTraining/{variation1}-frames'\n",
    "# save_path = f'/mnt/data/ataparia/LidarTraining/{variation1}-{variation2}-frames'\n",
    "\n",
    "# Create the save directory\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "# os.makedirs(f'{save_path}/training', exist_ok=True)\n",
    "# os.makedirs(f'{save_path}/validation', exist_ok=True)\n",
    "# os.makedirs(f'{save_path}/testing', exist_ok=True)\n",
    "\n",
    "all_sf_files = {\n",
    "    'dawn_dusk': [], \n",
    "    'day': [], \n",
    "    'night': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 798\n",
      "Number of validation files: 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files in training: 100%|██████████| 798/798 [00:26<00:00, 29.59it/s]\n",
      "Processing files in validation: 100%|██████████| 202/202 [00:06<00:00, 32.36it/s]\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(os.path.join(data_path, 'training'))\n",
    "train_files = [f for f in train_files if f.endswith('.tfrecord')]\n",
    "print('Number of training files:', len(train_files))\n",
    "\n",
    "val_files = os.listdir(os.path.join(data_path, 'validation'))\n",
    "val_files = [f for f in val_files if f.endswith('.tfrecord')]\n",
    "print('Number of validation files:', len(val_files))\n",
    "\n",
    "for f in tqdm(train_files, desc=\"Processing files in training\"):\n",
    "    filename = os.path.join(data_path, 'training', f)\n",
    "    dataset = tf.data.TFRecordDataset(filename, compression_type='')\n",
    "    for data in dataset:\n",
    "        frame = open_dataset.Frame()\n",
    "        frame.ParseFromString(bytearray(data.numpy()))\n",
    "        frame_stats = frame.context.stats\n",
    "        if frame_stats.location == 'location_sf':\n",
    "            time_of_day = frame_stats.time_of_day\n",
    "            if time_of_day == 'Night':\n",
    "                time_of_day = 'night'\n",
    "            elif time_of_day == 'Day':\n",
    "                time_of_day = 'day'\n",
    "            elif time_of_day == 'Dawn/Dusk':\n",
    "                time_of_day = 'dawn_dusk'   \n",
    "            all_sf_files[time_of_day].append(filename)\n",
    "        break\n",
    "\n",
    "# Validation split\n",
    "for f in tqdm(val_files, desc=\"Processing files in validation\"):\n",
    "    filename = os.path.join(data_path, 'validation', f)\n",
    "    dataset = tf.data.TFRecordDataset(filename, compression_type='')\n",
    "    for data in dataset:\n",
    "        frame = open_dataset.Frame()\n",
    "        frame.ParseFromString(bytearray(data.numpy()))\n",
    "        frame_stats = frame.context.stats\n",
    "        if frame_stats.location == 'location_sf':\n",
    "            time_of_day = frame_stats.time_of_day\n",
    "            if time_of_day == 'Night':\n",
    "                time_of_day = 'night'\n",
    "            elif time_of_day == 'Day':\n",
    "                time_of_day = 'day'\n",
    "            elif time_of_day == 'Dawn/Dusk':\n",
    "                time_of_day = 'dawn_dusk'            \n",
    "            all_sf_files[time_of_day].append(filename)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 46/46 [00:41<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of night files: 9097\n",
      "Variation: night\n",
      "Number of train files: 7277\n",
      "Number of val files: 910\n",
      "Number of test files: 910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "video_to_frames = []\n",
    "\n",
    "files1 = all_sf_files[variation1]\n",
    "\n",
    "for f in tqdm(files1, desc=\"Processing files\"):\n",
    "    filename = f\n",
    "    dataset = tf.data.TFRecordDataset(filename, compression_type='')\n",
    "    for data in dataset:\n",
    "        frame = open_dataset.Frame()\n",
    "        frame.ParseFromString(bytearray(data.numpy()))\n",
    "        \n",
    "        video_to_frames.append(frame)\n",
    "\n",
    "\n",
    "random.shuffle(video_to_frames)\n",
    "\n",
    "\n",
    "print(f'Number of {variation1} files:', len(video_to_frames))\n",
    "\n",
    "train_files1 = video_to_frames[:int(0.8*len(video_to_frames))]\n",
    "val_files1 = video_to_frames[int(0.8*len(video_to_frames)):int(0.9*len(video_to_frames))]\n",
    "test_files1 = video_to_frames[int(0.9*len(video_to_frames)):]\n",
    "\n",
    "print('Variation:', variation1)\n",
    "print('Number of train files:', len(train_files1))\n",
    "print('Number of val files:', len(val_files1))\n",
    "print('Number of test files:', len(test_files1))\n",
    "\n",
    "split_frames = {\n",
    "    'training': train_files1,\n",
    "    'validation': val_files1,\n",
    "    'testing': test_files1\n",
    "}\n",
    "\n",
    "\n",
    "# video_to_frames = []\n",
    "\n",
    "# files2 = all_sf_files[variation2]\n",
    "\n",
    "# for f in tqdm(files2, desc=\"Processing files\"):\n",
    "#     filename = f\n",
    "#     dataset = tf.data.TFRecordDataset(filename, compression_type='')\n",
    "#     for data in dataset:\n",
    "#         frame = open_dataset.Frame()\n",
    "#         frame.ParseFromString(bytearray(data.numpy()))\n",
    "        \n",
    "#         video_to_frames.append(frame)\n",
    "    \n",
    "# random.shuffle(video_to_frames)\n",
    "\n",
    "# print(f'Number of {variation2} files:', len(video_to_frames))\n",
    "\n",
    "# train_files2 = video_to_frames[:int(0.8*len(video_to_frames))]\n",
    "# val_files2 = video_to_frames[int(0.8*len(video_to_frames)):int(0.9*len(video_to_frames))]\n",
    "# test_files2 = video_to_frames[int(0.9*len(video_to_frames)):]\n",
    "\n",
    "# print('Variation:', variation2)\n",
    "# print('Number of train files:', len(train_files2))\n",
    "# print('Number of val files:', len(val_files2))\n",
    "# print('Number of test files:', len(test_files2))\n",
    "\n",
    "# split_frames = {\n",
    "#     'training': train_files1 + train_files2,\n",
    "#     'validation': val_files1 + val_files2,\n",
    "#     'testing': test_files1 + test_files2\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(video_to_frames)\n",
    "\n",
    "# print(f'Number of {variation} files:', len(video_to_frames))\n",
    "\n",
    "# train_files = video_to_frames[:int(0.8*len(video_to_frames))]\n",
    "# val_files = video_to_frames[int(0.8*len(video_to_frames)):int(0.9*len(video_to_frames))]\n",
    "# test_files = video_to_frames[int(0.9*len(video_to_frames)):]\n",
    "\n",
    "# print('Number of train files:', len(train_files))\n",
    "# print('Number of val files:', len(val_files))\n",
    "# print('Number of test files:', len(test_files))\n",
    "\n",
    "# split_frames = {\n",
    "#     'training': train_files,\n",
    "#     'validation': val_files,\n",
    "#     'testing': test_files\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path as osp\n",
    "from mmengine import print_log\n",
    "\n",
    "from create_gt_database import GTDatabaseCreater, create_groundtruth_database\n",
    "from update_infos_to_v2 import update_pkl_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v1.4'\n",
    "max_sweeps = 1\n",
    "workers = 0\n",
    "extra_tag = 'waymo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def waymo_data_prep(frame_dict,\n",
    "#                     info_prefix,\n",
    "#                     version,\n",
    "#                     out_dir,\n",
    "#                     workers,\n",
    "#                     max_sweeps=1,\n",
    "#                     only_gt_database=False,\n",
    "#                     save_senor_data=True,\n",
    "#                     skip_cam_instances_infos=False):\n",
    "#     \"\"\"Prepare waymo dataset. There are 3 steps as follows:\n",
    "\n",
    "#     Step 1. Extract camera images and lidar point clouds from waymo raw\n",
    "#         data in '*.tfreord' and save as kitti format.\n",
    "#     Step 2. Generate waymo train/val/test infos and save as pickle file.\n",
    "#     Step 3. Generate waymo ground truth database (point clouds within\n",
    "#         each 3D bounding box) for data augmentation in training.\n",
    "#     Steps 1 and 2 will be done in Waymo2KITTI, and step 3 will be done in\n",
    "#     GTDatabaseCreater.\n",
    "\n",
    "#     Args:\n",
    "#         root_path (str): Path of dataset root.\n",
    "#         info_prefix (str): The prefix of info filenames.\n",
    "#         out_dir (str): Output directory of the generated info file.\n",
    "#         workers (int): Number of threads to be used.\n",
    "#         max_sweeps (int, optional): Number of input consecutive frames.\n",
    "#             Default to 10. Here we store ego2global information of these\n",
    "#             frames for later use.\n",
    "#         only_gt_database (bool, optional): Whether to only generate ground\n",
    "#             truth database. Default to False.\n",
    "#         save_senor_data (bool, optional): Whether to skip saving\n",
    "#             image and lidar. Default to False.\n",
    "#         skip_cam_instances_infos (bool, optional): Whether to skip\n",
    "#             gathering cam_instances infos in Step 2. Default to False.\n",
    "#     \"\"\"\n",
    "#     import waymo_converter as waymo\n",
    "\n",
    "#     if version == 'v1.4':\n",
    "#         splits = [\n",
    "#             'training', \n",
    "#             'validation', \n",
    "#             'testing'\n",
    "#             # , 'testing_3d_camera_only_detection'\n",
    "#         ]\n",
    "#     elif version == 'v1.4-mini':\n",
    "#         splits = ['training', 'validation']\n",
    "#     else:\n",
    "#         raise NotImplementedError(f'Unsupported Waymo version {version}!')\n",
    "#     # out_dir = osp.join(out_dir, 'kitti_format')\n",
    "\n",
    "#     if not only_gt_database:\n",
    "#         for i, split in enumerate(splits):\n",
    "#             # load_dir = osp.join(root_path, 'waymo_format', split)\n",
    "#             frames = frame_dict[split]\n",
    "#             if split == 'validation':\n",
    "#                 save_dir = osp.join(out_dir, 'training')\n",
    "#             else:\n",
    "#                 save_dir = osp.join(out_dir, split)\n",
    "#             converter = waymo.Waymo2KITTI(\n",
    "#                 # load_dir,\n",
    "#                 frames,\n",
    "#                 save_dir,\n",
    "#                 prefix=str(i),\n",
    "#                 workers=workers,\n",
    "#                 test_mode=(split\n",
    "#                            in ['testing', 'testing_3d_camera_only_detection']),\n",
    "#                 info_prefix=info_prefix,\n",
    "#                 max_sweeps=max_sweeps,\n",
    "#                 split=split,\n",
    "#                 save_senor_data=save_senor_data,\n",
    "#                 save_cam_instances=not skip_cam_instances_infos)\n",
    "#             converter.convert()\n",
    "#             if split == 'validation':\n",
    "#                 converter.merge_trainval_infos()\n",
    "\n",
    "#         from waymo_converter import create_ImageSets_img_ids\n",
    "#         create_ImageSets_img_ids(out_dir, splits)\n",
    "\n",
    "#     GTDatabaseCreater(\n",
    "#         'WaymoDataset',\n",
    "#         out_dir,\n",
    "#         info_prefix,\n",
    "#         f'{info_prefix}_infos_train.pkl',\n",
    "#         relative_path=False,\n",
    "#         with_mask=False,\n",
    "#         num_worker=workers).create()\n",
    "\n",
    "#     print_log('Successfully preparing Waymo Open Dataset')\n",
    "\n",
    "def waymo_data_prep(frame_dict,\n",
    "                    info_prefix,\n",
    "                    version,\n",
    "                    out_dir,\n",
    "                    workers,\n",
    "                    max_sweeps=1,\n",
    "                    only_gt_database=False,\n",
    "                    save_senor_data=True,\n",
    "                    skip_cam_instances_infos=False):\n",
    "    \"\"\"Prepare waymo dataset. There are 3 steps as follows:\n",
    "\n",
    "    Step 1. Extract camera images and lidar point clouds from waymo raw\n",
    "        data in '*.tfreord' and save as kitti format.\n",
    "    Step 2. Generate waymo train/val/test infos and save as pickle file.\n",
    "    Step 3. Generate waymo ground truth database (point clouds within\n",
    "        each 3D bounding box) for data augmentation in training.\n",
    "    Steps 1 and 2 will be done in Waymo2KITTI, and step 3 will be done in\n",
    "    GTDatabaseCreater.\n",
    "\n",
    "    Args:\n",
    "        root_path (str): Path of dataset root.\n",
    "        info_prefix (str): The prefix of info filenames.\n",
    "        out_dir (str): Output directory of the generated info file.\n",
    "        workers (int): Number of threads to be used.\n",
    "        max_sweeps (int, optional): Number of input consecutive frames.\n",
    "            Default to 10. Here we store ego2global information of these\n",
    "            frames for later use.\n",
    "        only_gt_database (bool, optional): Whether to only generate ground\n",
    "            truth database. Default to False.\n",
    "        save_senor_data (bool, optional): Whether to skip saving\n",
    "            image and lidar. Default to False.\n",
    "        skip_cam_instances_infos (bool, optional): Whether to skip\n",
    "            gathering cam_instances infos in Step 2. Default to False.\n",
    "    \"\"\"\n",
    "    import waymo_converter as waymo\n",
    "\n",
    "    if version == 'v1.4':\n",
    "        splits = [\n",
    "            'training', \n",
    "            'validation', \n",
    "            'testing'\n",
    "            # , 'testing_3d_camera_only_detection'\n",
    "        ]\n",
    "    elif version == 'v1.4-mini':\n",
    "        splits = ['training', 'validation']\n",
    "    else:\n",
    "        raise NotImplementedError(f'Unsupported Waymo version {version}!')\n",
    "    # out_dir = osp.join(out_dir, 'kitti_format')\n",
    "\n",
    "    if not only_gt_database:\n",
    "        for i, split in enumerate(splits):\n",
    "            # load_dir = osp.join(root_path, 'waymo_format', split)\n",
    "            frames = frame_dict[split]\n",
    "            if frames.__len__() == 0:\n",
    "                continue\n",
    "            \n",
    "            if split == 'validation' or split == 'training':\n",
    "                continue\n",
    "            \n",
    "            if split == 'validation':\n",
    "                save_dir = osp.join(out_dir, 'training')\n",
    "            else:\n",
    "                save_dir = osp.join(out_dir, split)\n",
    "            converter = waymo.Waymo2KITTI(\n",
    "                # load_dir,\n",
    "                frames,\n",
    "                save_dir,\n",
    "                prefix=str(i),\n",
    "                workers=workers,\n",
    "                test_mode=(split\n",
    "                           in ['testing_3d_camera_only_detection']),\n",
    "                info_prefix=info_prefix,\n",
    "                max_sweeps=max_sweeps,\n",
    "                split=split,\n",
    "                save_senor_data=save_senor_data,\n",
    "                save_cam_instances=not skip_cam_instances_infos)\n",
    "            converter.convert()\n",
    "            if split == 'validation':\n",
    "                converter.merge_trainval_infos()\n",
    "\n",
    "        from waymo_converter import create_ImageSets_img_ids\n",
    "        create_ImageSets_img_ids(out_dir, splits)\n",
    "\n",
    "\n",
    "    # GTDatabaseCreater(\n",
    "    #     'WaymoDataset',\n",
    "    #     out_dir,\n",
    "    #     info_prefix,\n",
    "    #     f'{info_prefix}_infos_train.pkl',\n",
    "    #     relative_path=False,\n",
    "    #     with_mask=False,\n",
    "    #     num_worker=workers).create()\n",
    "\n",
    "    print_log('Successfully preparing Waymo Open Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/13 14:04:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Start converting testing dataset\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 910/910, 1.0 task/s, elapsed: 888s, ETA:     0s\n",
      "Saving testing dataset infos into /mnt/data/ataparia/LidarTraining/night-frames/waymo_infos_test.pkl\n",
      "created txt files indicating what to collect in  ['training', 'validation', 'testing']\n",
      "Successfully preparing Waymo Open Dataset\n"
     ]
    }
   ],
   "source": [
    "waymo_data_prep(\n",
    "            frame_dict=split_frames,\n",
    "            info_prefix=extra_tag,\n",
    "            version=version,\n",
    "            out_dir=save_path,\n",
    "            workers=workers,\n",
    "            save_senor_data=True,\n",
    "            max_sweeps=max_sweeps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/mnt/data/ataparia/LidarTraining/night-frames/waymo_infos_test.pkl'\n",
    "\n",
    "# import os\n",
    "# import pickle\n",
    "\n",
    "# def read_pickle(file_path, suffix='.pkl'):\n",
    "#     assert os.path.splitext(file_path)[1] == suffix\n",
    "#     with open(file_path, 'rb') as f:\n",
    "#         data = pickle.load(f)\n",
    "#     return data\n",
    "\n",
    "# data = read_pickle(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
